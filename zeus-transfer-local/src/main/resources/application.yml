server:
  port: 8899
spring:
  application:
    name: zeus-transfer-local
  datasource:
    type: com.zaxxer.hikari.HikariDataSource
    url: jdbc:mysql://${SPRING_DATASOURCE_URL:127.0.0.1}:3306/zeus-transfer?characterEncoding=utf8&useSSL=false&allowPublicKeyRetrieval=true&&serverTimezone=UTC
    username: ${SPRING_DATASOURCE_USERNAME:root}
    password: ${SPRING_DATASOURCE_PASSWORD:root}
    hikari:
      connection-timeout: 30000
      max-lifetime: 1800000
  jpa:
    database: MYSQL
    hibernate:
      ddl-auto: none
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
    show-sql: false
    open-in-view: false
  quartz:
    #相关属性配置
    properties:
      org:
        quartz:
          scheduler:
            instanceName: clusteredScheduler
            instanceId: AUTO
          threadPool:
            class: org.quartz.simpl.SimpleThreadPool
            threadCount: 10
            threadPriority: 5
            threadsInheritContextClassLoaderOfInitializingThread: true
    job-store-type: MEMORY
  security:
    user:
      name: admin #账号
      password: admin  #密码
  kafka:
    bootstrap-servers: load.balance.com:9290
    # 消费监听接口监听的主题不存在时，默认会报错
    listener:
      missing-topics-fatal: false
    producer:
      # 当retries为0时，produce不会重复。retries重发，此时retries节点完全成为leader节点，不会产生消息丢失。
      retries: 0
      #procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：
      #acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
      #acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应，在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
      #acks = all 这意味着leader将等待完整的同步副本集以确认记录，这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证，这相当于acks = -1的设置。
      #可以设置的值为：all, -1, 0, 1
      acks: all
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 每次批量发送消息的数量,produce积累到一定数据，一次发送
      #batch-size: 16384
      # produce积累数据一次发送，缓存大小达到buffer.memory就发送数据
      #buffer-memory: 33554432
    consumer:
      # 指定默认消费者group id --> 由于在kafka中，同一组中的consumer不会读取到同一个消息，依靠groud.id设置组名
      group-id: chengdubudui-zeusGroup
      # smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
      auto-offset-reset: earliest
      # enable.auto.commit:true --> 设置自动提交offset
      enable-auto-commit: false
      #如果enable.auto.commit为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
      auto-commit-interval: 100
#      max.poll.records: 300
#      session.timeout.ms: 600000
#      request.timeout.ms: 600000
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    security:
      protocol: SASL_PLAINTEXT
    properties:
      sasl.mechanism: SCRAM-SHA-512
      sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username='chengdubudui' password='1234567';
management:
  endpoints:
    web:
      exposure:
        include: 'loggers'
  endpoint:
    health:
      show-details: always
logging:
  file:
    name: /logs/${spring.application.name}/${spring.application.name}.log
custom:
  query:
    filter-word:
    related-query:
      related: D2809*(脱轨+列车+动车),D2809*(贵州+榕江站+贵阳),北京*疫情,上海*疫情,俄罗斯*乌克兰*冲突,俄乌冲突,俄乌局势,俄乌战争,俄乌战况,俄罗斯*乌克兰*局势,俄罗斯*乌克兰*战争,俄罗斯*乌克兰*战况,俄乌谈判,俄罗斯*乌克兰*谈判,3月21日东航客机事故,东航*(坠机+坠毁+事故),(巴基斯坦+卡拉奇)*3名中国公民*(身亡+死亡+遇难)
      exclustion: 电影,奶茶,体育,文化节,粉丝,老鼠,宠物,基金,投资,美股,票务,近景,远景,日景,夜景,雪景,抖音购物,蓝天白云,革命先烈,房屋租金,租房,萤火虫,购车
      carrier:
    author-query:
      author:
      carrier:
  es:
    version: 5
    page-size: ${CUSTOM_ES_PAGE_SIZE:1000}
    max-page-number: -1
    file-path: ${CUSTOM_ES_FILE_PATH:E:/北京武警学院数据/2022-03-08/8/}
    read-model: ${CUSTOM_ES_READ_MODEL:File}
    analysis: ${CUSTOM_ES_ANALYSIS:http://192.168.199.241:8080}
    search-type: ${CUSTOM_ES_SEARCH_TYPE:EXACT}
    search-range: PUBLISH_TIME
    es5: #es配置信息
      #      key: yq_test
      key: ${CUSTOM_ES_ES5_KEY:yq_test}
      host: ${CUSTOM_ES_ES5_HOST:http://river.junquan.com.cn}
      app-id: 1231231
      full-query: ${CUSTOM_ES_ES5_FULL_QUERY:/river/river/dataQuery}
      article-query: ${CUSTOM_ES_ES5_ARTICLE_QUERY:/index/query/queryByIdsWithContent}
  quartz:
    corn: ${CUSTOM_QUARTZ_CORN:0 */1 * * * ?}
    #    YEAR, MONTH, DAY, HOUR, MINUTE, SECOND,
    time-type: ${CUSTOM_QUARTZ_TIME_TYPE:MINUTE}
    #    开始时间提前多少 需要跟corn对应
    time-range: ${CUSTOM_QUARTZ_TIME_RANGE:-999}
    #    CUSTOM_AUTHOR(自定义作者) CUSTOM_WORD(自定义词) GATHER_WORD（词库中gather表）GATHER_AUTHOR（词库中author表） PUSH_ARTICLE 推送
    job-Type: ${CUSTOM_QUARTZ_JOB_TYPE:CUSTOM_WORD}
    #    true 开启  false 关闭
    state: ${CUSTOM_QUARTZ_STATE:false}
  kafka:
    topic: chengdubudui


